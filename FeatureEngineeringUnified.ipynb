{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4866f5e",
   "metadata": {},
   "source": [
    "# 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7b77e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.ml as ml\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5003dc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"YourAppName\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e491689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dfs():\n",
    "    global movies, users, ratings\n",
    "    movies = spark.read.csv(\"./Data/movieLens/movies.dat\", sep=\"::\", encoding=\"latin1\")\n",
    "    movies = movies.toDF(\"movie_id\", \"movie_name\", \"genre\").cache()\n",
    "    movies.createOrReplaceTempView(\"movies_info\")\n",
    "    \n",
    "    users = spark.read.csv(\"./Data/movieLens/users.dat\", sep=\"::\", encoding=\"latin1\")\n",
    "    users = users.toDF(\"user_id\", \"gender\", \"age\", \"occupation\", \"zipcode\").cache()\n",
    "    users.createOrReplaceTempView(\"users_info\")\n",
    "    \n",
    "    ratings = spark.read.csv(\"./Data/movieLens/ratings.dat\", sep=\"::\", encoding=\"latin1\")\n",
    "    ratings = ratings.toDF(\"user_id\", \"movie_id\", \"rating\", \"time_stamp\").cache()\n",
    "    ratings.createOrReplaceTempView(\"ratings_info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "903c27c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db93776e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+\n",
      "|movie_id|          movie_name|               genre|\n",
      "+--------+--------------------+--------------------+\n",
      "|       1|    Toy Story (1995)|Animation|Childre...|\n",
      "|       2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|       3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|       4|Waiting to Exhale...|        Comedy|Drama|\n",
      "|       5|Father of the Bri...|              Comedy|\n",
      "+--------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e51a16a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---+----------+-------+\n",
      "|user_id|gender|age|occupation|zipcode|\n",
      "+-------+------+---+----------+-------+\n",
      "|      1|     F|  1|        10|  48067|\n",
      "|      2|     M| 56|        16|  70072|\n",
      "|      3|     M| 25|        15|  55117|\n",
      "|      4|     M| 45|         7|  02460|\n",
      "|      5|     M| 25|        20|  55455|\n",
      "+-------+------+---+----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c7b23de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------+----------+\n",
      "|user_id|movie_id|rating|time_stamp|\n",
      "+-------+--------+------+----------+\n",
      "|      1|    1193|     5| 978300760|\n",
      "|      1|     661|     3| 978302109|\n",
      "|      1|     914|     3| 978301968|\n",
      "|      1|    3408|     4| 978300275|\n",
      "|      1|    2355|     5| 978824291|\n",
      "+-------+--------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6611a417",
   "metadata": {},
   "source": [
    "# 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045b4abb",
   "metadata": {},
   "source": [
    "## 2.1. Checking Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6db1b459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_null(df):\n",
    "    for col in df.columns:\n",
    "        empty = df.filter(df[col].isNull()).count()\n",
    "        print(f\"For columns {col}:\\t{empty} null records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "351ed4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For columns movie_id:\t0 null records\n",
      "For columns movie_name:\t0 null records\n",
      "For columns genre:\t0 null records\n"
     ]
    }
   ],
   "source": [
    "inspect_null(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4f40f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For columns user_id:\t0 null records\n",
      "For columns gender:\t0 null records\n",
      "For columns age:\t0 null records\n",
      "For columns occupation:\t0 null records\n",
      "For columns zipcode:\t0 null records\n"
     ]
    }
   ],
   "source": [
    "inspect_null(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1bbd8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For columns user_id:\t0 null records\n",
      "For columns movie_id:\t0 null records\n",
      "For columns rating:\t0 null records\n",
      "For columns time_stamp:\t0 null records\n"
     ]
    }
   ],
   "source": [
    "inspect_null(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3c7a18",
   "metadata": {},
   "source": [
    "## 2.2. Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b5457c",
   "metadata": {},
   "source": [
    "### 2.2.1. User dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a5ea154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- zipcode: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee258331",
   "metadata": {},
   "source": [
    "**Gender**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd9ebe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = users.withColumn(\"gender\", pyspark.sql.functions.when(users[\"gender\"] == 'M', 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fb87cd",
   "metadata": {},
   "source": [
    "**Mapping Age to Age Category**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5abf88a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType, IntegerType\n",
    "\n",
    "label_mapping = {\n",
    "    1: 1,\n",
    "    18: 2,\n",
    "    25: 3,\n",
    "    35: 4,\n",
    "    45: 5,\n",
    "    50: 6,\n",
    "    56: 7\n",
    "}\n",
    "\n",
    "age_udf = udf(lambda record: label_mapping[int(record)], IntegerType())\n",
    "users = users.withColumn(\"age\", age_udf(users[\"age\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c863a5d",
   "metadata": {},
   "source": [
    "**Mapping Zipcode to Region**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "995a29fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For columns user_id:\t0 null records\n",
      "For columns gender:\t0 null records\n",
      "For columns age:\t0 null records\n",
      "For columns occupation:\t0 null records\n",
      "For columns zipcode:\t0 null records\n",
      "For columns casted_zipcode:\t66 null records\n"
     ]
    }
   ],
   "source": [
    "users = users.withColumn(\"casted_zipcode\", users[\"zipcode\"].cast(IntegerType()))\n",
    "inspect_null(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1270c584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---+----------+----------+--------------+\n",
      "|user_id|gender|age|occupation|   zipcode|casted_zipcode|\n",
      "+-------+------+---+----------+----------+--------------+\n",
      "|    161|     1|  5|        16|98107-2117|          NULL|\n",
      "|    233|     0|  5|        20|37919-4204|          NULL|\n",
      "|    293|     1|  7|         1|55337-4056|          NULL|\n",
      "|    458|     1|  6|        16|55405-2546|          NULL|\n",
      "|    506|     1|  3|        16|55103-1006|          NULL|\n",
      "|    567|     1|  4|        20|52570-9634|          NULL|\n",
      "|    868|     1|  6|        17|01702-7224|          NULL|\n",
      "|    913|     1|  3|         0|20744-6223|          NULL|\n",
      "|    939|     0|  3|        20|20110-5616|          NULL|\n",
      "|    946|     1|  4|         7|48103-8929|          NULL|\n",
      "+-------+------+---+----------+----------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users.filter(users[\"casted_zipcode\"].isNull()).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e2a88b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_region(record):\n",
    "    record = str(record)\n",
    "    return int(record[0])\n",
    "\n",
    "zipcode_udf = udf(lambda record: to_region(record), IntegerType())\n",
    "users = users.withColumn(\"region\", zipcode_udf(users[\"zipcode\"]))\n",
    "users = users.drop(\"zipcode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5661891f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For columns user_id:\t0 null records\n",
      "For columns gender:\t0 null records\n",
      "For columns age:\t0 null records\n",
      "For columns occupation:\t0 null records\n",
      "For columns casted_zipcode:\t66 null records\n",
      "For columns region:\t0 null records\n"
     ]
    }
   ],
   "source": [
    "inspect_null(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae53789f",
   "metadata": {},
   "source": [
    "**Asserting that All the data are in integer type with no nulls**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d106bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For columns user_id:\t0 null records\n",
      "For columns gender:\t0 null records\n",
      "For columns age:\t0 null records\n",
      "For columns occupation:\t0 null records\n",
      "For columns casted_zipcode:\t66 null records\n",
      "For columns region:\t0 null records\n"
     ]
    }
   ],
   "source": [
    "for col in users.columns:\n",
    "    users = users.withColumn(col, users[col].cast(IntegerType()))\n",
    "    \n",
    "inspect_null(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b9d0d3",
   "metadata": {},
   "source": [
    "### 2.2.2. For Movies Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8307451e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movie_id: string (nullable = true)\n",
      " |-- movie_name: string (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76ffc7b",
   "metadata": {},
   "source": [
    "**Transforming movies_id to integer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "772357b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.withColumn(\"movie_id\", movies[\"movie_id\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f190b3",
   "metadata": {},
   "source": [
    "**Parsing movie_name to year and name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b506acab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_date(record):\n",
    "    pattern  = r'\\((\\d{4})\\)'\n",
    "    if re.findall(pattern, record.strip()[-6:]):\n",
    "        return int(record.strip()[-5:-1])\n",
    "    return None\n",
    "\n",
    "def extract_name(record):\n",
    "    pattern  = r'\\((\\d{4})\\)'\n",
    "    if re.findall(pattern, record.strip()[-6:]):\n",
    "        return record.strip()[:-6].strip()\n",
    "    return record\n",
    "\n",
    "# Define UDFs for extract_date and extract_name functions\n",
    "extract_date_udf = udf(lambda record: extract_date(record), IntegerType())\n",
    "extract_name_udf = udf(lambda record: extract_name(record), StringType())\n",
    "\n",
    "movies = movies.withColumn(\"year\", extract_date_udf(movies[\"movie_name\"]))\n",
    "movies = movies.withColumn(\"name\", extract_name_udf(movies[\"movie_name\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122a9707",
   "metadata": {},
   "source": [
    "**Parsing the genre into a serie of genres**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "604f87cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.withColumn(\"parsed_genre\", pyspark.sql.functions.explode(pyspark.sql.functions.split(movies[\"genre\"], \"\\\\s*\\\\|\\\\s*\")))\n",
    "movies = movies.withColumn(\"value\", (movies[\"parsed_genre\"]==movies[\"parsed_genre\"]).cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8a5046",
   "metadata": {},
   "source": [
    "### 2.2.3. For Ratings Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3babc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- movie_id: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- time_stamp: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49988ca6",
   "metadata": {},
   "source": [
    "**Casting All the attributes to int type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea30d6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- movie_id: integer (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      " |-- time_stamp: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in ratings.columns:\n",
    "    ratings = ratings.withColumn(col, ratings[col].cast(IntegerType()))\n",
    "\n",
    "ratings.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5222f8ff",
   "metadata": {},
   "source": [
    "# 3. Saving The cleaned datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8c5c80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.toPandas().to_csv(\"./Data/cleaned_data/ratings.csv\", header=True)\n",
    "movies.toPandas().to_csv(\"./Data/cleaned_data/movies.csv\", header=True)\n",
    "users.toPandas().to_csv(\"./Data/cleaned_data/users.csv\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884bed97",
   "metadata": {},
   "source": [
    "# 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78c93ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.createOrReplaceTempView(\"movies_info\")\n",
    "users.createOrReplaceTempView(\"users_info\")\n",
    "ratings.createOrReplaceTempView(\"ratings_info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1da82a",
   "metadata": {},
   "source": [
    "## 4.1. Movies Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3b8b13",
   "metadata": {},
   "source": [
    "**Features used for the movie:**\n",
    "1. year\n",
    "2. genres\n",
    "3. watch_count\n",
    "4. popularity among its genre\n",
    "5. avarage rating\n",
    "6. rating ratio per genre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a103491",
   "metadata": {},
   "source": [
    "**watch count**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "26d763c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "popularity = spark.sql(\"SELECT movie_id, COUNT(DISTINCT(user_id)) AS watches FROM ratings_info GROUP BY movie_id\")\n",
    "popularity.createOrReplaceTempView(\"popularity_info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad6fe95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n",
      "|movie_id|watches|\n",
      "+--------+-------+\n",
      "|    1580|   2538|\n",
      "|     471|    599|\n",
      "|    3175|   1728|\n",
      "|    1959|    626|\n",
      "|    3794|    121|\n",
      "+--------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "popularity.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020beb56",
   "metadata": {},
   "source": [
    "**Popularity among its genre**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8997ecfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    SELECT parsed_genre AS genre, COUNT(user_id) AS genre_count\n",
    "    FROM   ratings_info LEFT JOIN movies_info ON movies_info.movie_id = ratings_info.movie_id  \n",
    "    GROUP BY parsed_genre\n",
    "\"\"\"\n",
    "\n",
    "watches_per_genre = spark.sql(query)\n",
    "watches_per_genre.createOrReplaceTempView(\"watches_per_genre_info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f7139064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|    genre|genre_count|\n",
      "+---------+-----------+\n",
      "|    Crime|      79541|\n",
      "|  Romance|     147523|\n",
      "| Thriller|     189680|\n",
      "|Adventure|     133953|\n",
      "|    Drama|     354529|\n",
      "+---------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "watches_per_genre.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b2d1197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+-------+---------+-----------+--------------------+\n",
      "|movie_id|year|watches|    genre|genre_count|popularity_per_genre|\n",
      "+--------+----+-------+---------+-----------+--------------------+\n",
      "|    1580|1997|   2538|   Sci-Fi|     157294|  0.0161353897796483|\n",
      "|    1580|1997|   2538|   Comedy|     356580|0.007117617364967188|\n",
      "|    1580|1997|   2538|Adventure|     133953| 0.01894694407740028|\n",
      "|    1580|1997|   2538|   Action|     257457|0.009857956862699403|\n",
      "|     471|1994|    599|  Romance|     147523|0.004060383804559289|\n",
      "+--------+----+-------+---------+-----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "    SELECT *, watches/genre_count AS popularity_per_genre\n",
    "    FROM    (SELECT movies_info.movie_id AS movie_id, year, parsed_genre, watches\n",
    "             FROM   movies_info INNER JOIN popularity_info ON movies_info.movie_id = popularity_info.movie_id\n",
    "            ) A INNER JOIN \n",
    "            watches_per_genre_info ON A.parsed_genre = watches_per_genre_info.genre\n",
    "\"\"\"\n",
    "\n",
    "df = spark.sql(query)\n",
    "df = df.drop(\"parsed_genre\")\n",
    "df.createOrReplaceTempView(\"df_info\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde96d7e",
   "metadata": {},
   "source": [
    "**Avarage Rating**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8889c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|movie_id|        avg_rating|\n",
      "+--------+------------------+\n",
      "|    1580| 3.739952718676123|\n",
      "|    2366|3.6560846560846563|\n",
      "|    1088|3.3114992721979624|\n",
      "|    1959|3.6533546325878596|\n",
      "|    3175| 3.771412037037037|\n",
      "+--------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "    SELECT movie_id, AVG(rating) AS avg_rating \n",
    "    FROM ratings_info \n",
    "    GROUP BY movie_id\n",
    "\"\"\"\n",
    "\n",
    "avg = spark.sql(query)\n",
    "avg.createOrReplaceTempView(\"avg_info\")\n",
    "avg.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c134950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+----+-------+-----------+--------------------+-----------------+\n",
      "|movie_id|    genre|year|watches|genre_count|popularity_per_genre|       avg_rating|\n",
      "+--------+---------+----+-------+-----------+--------------------+-----------------+\n",
      "|    1580|   Sci-Fi|1997|   2538|     157294|  0.0161353897796483|3.739952718676123|\n",
      "|    1580|   Comedy|1997|   2538|     356580|0.007117617364967188|3.739952718676123|\n",
      "|    1580|Adventure|1997|   2538|     133953| 0.01894694407740028|3.739952718676123|\n",
      "|    1580|   Action|1997|   2538|     257457|0.009857956862699403|3.739952718676123|\n",
      "|     471|  Romance|1994|    599|     147523|0.004060383804559289|3.631051752921536|\n",
      "+--------+---------+----+-------+-----------+--------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "    SELECT A.movie_id, genre, year, watches, genre_count, popularity_per_genre, avg_rating\n",
    "    FROM   df_info AS A LEFT JOIN avg_info ON A.movie_id = avg_info.movie_id\n",
    "\"\"\"\n",
    "\n",
    "df = spark.sql(query)\n",
    "df.createOrReplaceTempView(\"df_info\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca76ab60",
   "metadata": {},
   "source": [
    "**rating ratio to genre rating**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "88459f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|    genre| mean_genre_rating|\n",
      "+---------+------------------+\n",
      "|    Crime| 3.708678543141273|\n",
      "|  Romance| 3.607464598740535|\n",
      "| Thriller|3.5704660480809784|\n",
      "|Adventure| 3.477256948332624|\n",
      "|    Drama| 3.766332232342065|\n",
      "+---------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "    SELECT A.parsed_genre AS genre, MEAN(B.rating) AS mean_genre_rating\n",
    "    FROM   movies_info AS A JOIN ratings_info B ON A.movie_id = B.movie_id\n",
    "    GROUP BY A.parsed_genre\n",
    "\"\"\"\n",
    "\n",
    "avg = spark.sql(query)\n",
    "avg.createOrReplaceTempView(\"avg_info\")\n",
    "avg.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d4b63896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+----+-------+--------------------+-----------------+------------------+\n",
      "|movie_id|    genre|year|watches|popularity_per_genre|       avg_rating|  rating_per_genre|\n",
      "+--------+---------+----+-------+--------------------+-----------------+------------------+\n",
      "|    1580|   Sci-Fi|1997|   2538|  0.0161353897796483|3.739952718676123|1.0788777579469762|\n",
      "|    1580|   Comedy|1997|   2538|0.007117617364967188|3.739952718676123|1.0618534293265696|\n",
      "|    1580|Adventure|1997|   2538| 0.01894694407740028|3.739952718676123|1.0755468388579865|\n",
      "|    1580|   Action|1997|   2538|0.009857956862699403|3.739952718676123|1.0712559739797276|\n",
      "|     471|  Romance|1994|    599|0.004060383804559289|3.631051752921536|1.0065384298405133|\n",
      "+--------+---------+----+-------+--------------------+-----------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "    SELECT A.movie_id, A.genre, A.year, watches, popularity_per_genre, avg_rating, avg_rating/mean_genre_rating AS rating_per_genre\n",
    "    FROM   df_info AS A LEFT JOIN avg_info B ON A.genre = B.genre\n",
    "\"\"\"\n",
    "\n",
    "df = spark.sql(query)\n",
    "df.createOrReplaceTempView(\"df_info\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3587e35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.toPandas().to_csv(\"./Data/cleaned_data/unpivoted_movies_features.csv\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49eb96b",
   "metadata": {},
   "source": [
    "### 4.1.2. Pivoting the Movies Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f07c89f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded = [\"movie_id\", \"year\", \"watches\", \"avg_rating\"]\n",
    "\n",
    "sub1 = df[[\"movie_id\", \"genre\", \"year\", \"watches\", \"avg_rating\", \"popularity_per_genre\"]]\n",
    "sub1 = sub1.groupBy([\"movie_id\", \"year\", \"watches\", \"avg_rating\"]).pivot(\"genre\").sum(\"popularity_per_genre\")\n",
    "\n",
    "columns = {col: 0 for col in sub1.columns if not(col in excluded)}\n",
    "sub1 = sub1.fillna(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "66da96d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movie_id: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- watches: long (nullable = false)\n",
      " |-- avg_rating: double (nullable = true)\n",
      " |-- Action: double (nullable = false)\n",
      " |-- Adventure: double (nullable = false)\n",
      " |-- Animation: double (nullable = false)\n",
      " |-- Children's: double (nullable = false)\n",
      " |-- Comedy: double (nullable = false)\n",
      " |-- Crime: double (nullable = false)\n",
      " |-- Documentary: double (nullable = false)\n",
      " |-- Drama: double (nullable = false)\n",
      " |-- Fantasy: double (nullable = false)\n",
      " |-- Film-Noir: double (nullable = false)\n",
      " |-- Horror: double (nullable = false)\n",
      " |-- Musical: double (nullable = false)\n",
      " |-- Mystery: double (nullable = false)\n",
      " |-- Romance: double (nullable = false)\n",
      " |-- Sci-Fi: double (nullable = false)\n",
      " |-- Thriller: double (nullable = false)\n",
      " |-- War: double (nullable = false)\n",
      " |-- Western: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sub1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "245b3467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movie_id: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- watches: long (nullable = false)\n",
      " |-- avg_rating: double (nullable = true)\n",
      " |-- popularity_per_Action: double (nullable = false)\n",
      " |-- popularity_per_Adventure: double (nullable = false)\n",
      " |-- popularity_per_Animation: double (nullable = false)\n",
      " |-- popularity_per_Children's: double (nullable = false)\n",
      " |-- popularity_per_Comedy: double (nullable = false)\n",
      " |-- popularity_per_Crime: double (nullable = false)\n",
      " |-- popularity_per_Documentary: double (nullable = false)\n",
      " |-- popularity_per_Drama: double (nullable = false)\n",
      " |-- popularity_per_Fantasy: double (nullable = false)\n",
      " |-- popularity_per_Film-Noir: double (nullable = false)\n",
      " |-- popularity_per_Horror: double (nullable = false)\n",
      " |-- popularity_per_Musical: double (nullable = false)\n",
      " |-- popularity_per_Mystery: double (nullable = false)\n",
      " |-- popularity_per_Romance: double (nullable = false)\n",
      " |-- popularity_per_Sci-Fi: double (nullable = false)\n",
      " |-- popularity_per_Thriller: double (nullable = false)\n",
      " |-- popularity_per_War: double (nullable = false)\n",
      " |-- popularity_per_Western: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "excluded = [\"movie_id\", \"year\", \"watches\", \"avg_rating\"]\n",
    "for col in sub1.columns:\n",
    "    if not(col in excluded):\n",
    "        sub1 = sub1.withColumnRenamed(col, \"popularity_per_\"+col)\n",
    "\n",
    "sub1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "18047576",
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded = [\"movie_id\", \"year\"]\n",
    "\n",
    "sub2 = df[[\"movie_id\", \"genre\", \"year\", \"rating_per_genre\"]]\n",
    "sub2 = sub2.groupBy([\"movie_id\", \"year\"]).pivot(\"genre\").sum(\"rating_per_genre\")\n",
    "\n",
    "columns = {col: 0 for col in sub2.columns if not(col in excluded)}\n",
    "sub2 = sub2.fillna(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6bb55813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movie_id: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- Action: double (nullable = false)\n",
      " |-- Adventure: double (nullable = false)\n",
      " |-- Animation: double (nullable = false)\n",
      " |-- Children's: double (nullable = false)\n",
      " |-- Comedy: double (nullable = false)\n",
      " |-- Crime: double (nullable = false)\n",
      " |-- Documentary: double (nullable = false)\n",
      " |-- Drama: double (nullable = false)\n",
      " |-- Fantasy: double (nullable = false)\n",
      " |-- Film-Noir: double (nullable = false)\n",
      " |-- Horror: double (nullable = false)\n",
      " |-- Musical: double (nullable = false)\n",
      " |-- Mystery: double (nullable = false)\n",
      " |-- Romance: double (nullable = false)\n",
      " |-- Sci-Fi: double (nullable = false)\n",
      " |-- Thriller: double (nullable = false)\n",
      " |-- War: double (nullable = false)\n",
      " |-- Western: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sub2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca0e1e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movie_id: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- rating_per_Action: double (nullable = false)\n",
      " |-- rating_per_Adventure: double (nullable = false)\n",
      " |-- rating_per_Animation: double (nullable = false)\n",
      " |-- rating_per_Children's: double (nullable = false)\n",
      " |-- rating_per_Comedy: double (nullable = false)\n",
      " |-- rating_per_Crime: double (nullable = false)\n",
      " |-- rating_per_Documentary: double (nullable = false)\n",
      " |-- rating_per_Drama: double (nullable = false)\n",
      " |-- rating_per_Fantasy: double (nullable = false)\n",
      " |-- rating_per_Film-Noir: double (nullable = false)\n",
      " |-- rating_per_Horror: double (nullable = false)\n",
      " |-- rating_per_Musical: double (nullable = false)\n",
      " |-- rating_per_Mystery: double (nullable = false)\n",
      " |-- rating_per_Romance: double (nullable = false)\n",
      " |-- rating_per_Sci-Fi: double (nullable = false)\n",
      " |-- rating_per_Thriller: double (nullable = false)\n",
      " |-- rating_per_War: double (nullable = false)\n",
      " |-- rating_per_Western: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "excluded = [\"movie_id\", \"year\"]\n",
    "for col in sub2.columns:\n",
    "    if not(col in excluded):\n",
    "        sub2 = sub2.withColumnRenamed(col, \"rating_per_\"+col)\n",
    "\n",
    "sub2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "11205664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movie_id: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- watches: long (nullable = false)\n",
      " |-- avg_rating: double (nullable = true)\n",
      " |-- popularity_per_Action: double (nullable = false)\n",
      " |-- popularity_per_Adventure: double (nullable = false)\n",
      " |-- popularity_per_Animation: double (nullable = false)\n",
      " |-- popularity_per_Children's: double (nullable = false)\n",
      " |-- popularity_per_Comedy: double (nullable = false)\n",
      " |-- popularity_per_Crime: double (nullable = false)\n",
      " |-- popularity_per_Documentary: double (nullable = false)\n",
      " |-- popularity_per_Drama: double (nullable = false)\n",
      " |-- popularity_per_Fantasy: double (nullable = false)\n",
      " |-- popularity_per_Film-Noir: double (nullable = false)\n",
      " |-- popularity_per_Horror: double (nullable = false)\n",
      " |-- popularity_per_Musical: double (nullable = false)\n",
      " |-- popularity_per_Mystery: double (nullable = false)\n",
      " |-- popularity_per_Romance: double (nullable = false)\n",
      " |-- popularity_per_Sci-Fi: double (nullable = false)\n",
      " |-- popularity_per_Thriller: double (nullable = false)\n",
      " |-- popularity_per_War: double (nullable = false)\n",
      " |-- popularity_per_Western: double (nullable = false)\n",
      " |-- rating_per_Action: double (nullable = false)\n",
      " |-- rating_per_Adventure: double (nullable = false)\n",
      " |-- rating_per_Animation: double (nullable = false)\n",
      " |-- rating_per_Children's: double (nullable = false)\n",
      " |-- rating_per_Comedy: double (nullable = false)\n",
      " |-- rating_per_Crime: double (nullable = false)\n",
      " |-- rating_per_Documentary: double (nullable = false)\n",
      " |-- rating_per_Drama: double (nullable = false)\n",
      " |-- rating_per_Fantasy: double (nullable = false)\n",
      " |-- rating_per_Film-Noir: double (nullable = false)\n",
      " |-- rating_per_Horror: double (nullable = false)\n",
      " |-- rating_per_Musical: double (nullable = false)\n",
      " |-- rating_per_Mystery: double (nullable = false)\n",
      " |-- rating_per_Romance: double (nullable = false)\n",
      " |-- rating_per_Sci-Fi: double (nullable = false)\n",
      " |-- rating_per_Thriller: double (nullable = false)\n",
      " |-- rating_per_War: double (nullable = false)\n",
      " |-- rating_per_Western: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sub1.createOrReplaceTempView(\"sub1_info\")\n",
    "sub2.createOrReplaceTempView(\"sub2_info\")\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT * \n",
    "        FROM sub1_info INNER JOIN sub2_info\n",
    "        USING (movie_id, year)\n",
    "\"\"\"\n",
    "\n",
    "sub1 = spark.sql(query)\n",
    "sub1.createOrReplaceTempView(\"sub1_info\")\n",
    "sub1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ef480276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For columns movie_id:\t0 null records\n",
      "For columns year:\t0 null records\n",
      "For columns watches:\t0 null records\n",
      "For columns avg_rating:\t0 null records\n",
      "For columns popularity_per_Action:\t0 null records\n",
      "For columns popularity_per_Adventure:\t0 null records\n",
      "For columns popularity_per_Animation:\t0 null records\n",
      "For columns popularity_per_Children's:\t0 null records\n",
      "For columns popularity_per_Comedy:\t0 null records\n",
      "For columns popularity_per_Crime:\t0 null records\n",
      "For columns popularity_per_Documentary:\t0 null records\n",
      "For columns popularity_per_Drama:\t0 null records\n",
      "For columns popularity_per_Fantasy:\t0 null records\n",
      "For columns popularity_per_Film-Noir:\t0 null records\n",
      "For columns popularity_per_Horror:\t0 null records\n",
      "For columns popularity_per_Musical:\t0 null records\n",
      "For columns popularity_per_Mystery:\t0 null records\n",
      "For columns popularity_per_Romance:\t0 null records\n",
      "For columns popularity_per_Sci-Fi:\t0 null records\n",
      "For columns popularity_per_Thriller:\t0 null records\n",
      "For columns popularity_per_War:\t0 null records\n",
      "For columns popularity_per_Western:\t0 null records\n",
      "For columns rating_per_Action:\t0 null records\n",
      "For columns rating_per_Adventure:\t0 null records\n",
      "For columns rating_per_Animation:\t0 null records\n",
      "For columns rating_per_Children's:\t0 null records\n",
      "For columns rating_per_Comedy:\t0 null records\n",
      "For columns rating_per_Crime:\t0 null records\n",
      "For columns rating_per_Documentary:\t0 null records\n",
      "For columns rating_per_Drama:\t0 null records\n",
      "For columns rating_per_Fantasy:\t0 null records\n",
      "For columns rating_per_Film-Noir:\t0 null records\n",
      "For columns rating_per_Horror:\t0 null records\n",
      "For columns rating_per_Musical:\t0 null records\n",
      "For columns rating_per_Mystery:\t0 null records\n",
      "For columns rating_per_Romance:\t0 null records\n",
      "For columns rating_per_Sci-Fi:\t0 null records\n",
      "For columns rating_per_Thriller:\t0 null records\n",
      "For columns rating_per_War:\t0 null records\n",
      "For columns rating_per_Western:\t0 null records\n"
     ]
    }
   ],
   "source": [
    "inspect_null(sub1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5795131c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1.toPandas().to_csv(\"./Data/cleaned_data/pivoted_movies_features.csv\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d73841",
   "metadata": {},
   "source": [
    "## 4.2. Users Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854231aa",
   "metadata": {},
   "source": [
    "**Features used for the user:**\n",
    "\n",
    "1. gender\n",
    "2. age class\n",
    "3. Occupation class\n",
    "4. Region\n",
    "5. Avarage ratings\n",
    "6. number of watched movies\n",
    "7. avarage rating per genre\n",
    "8. the mode year of the movies watched\n",
    "9. Median year of the movies watched\n",
    "\n",
    "**For missing category avarage rating & Popularity avarage rating impute with avarage rating of all users**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e2d75aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- gender: integer (nullable = false)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- occupation: integer (nullable = true)\n",
      " |-- casted_zipcode: integer (nullable = true)\n",
      " |-- region: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49401211",
   "metadata": {},
   "source": [
    "**Avarage ratings & number of watched movies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f30e710b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---+----------+------+------------------+--------------+\n",
      "|user_id|gender|age|occupation|region|        avg_rating|watched_movies|\n",
      "+-------+------+---+----------+------+------------------+--------------+\n",
      "|    148|     1|  6|        17|     5| 3.733974358974359|           624|\n",
      "|    463|     1|  3|         7|     5|               3.0|           123|\n",
      "|    471|     1|  4|         7|     0|3.6285714285714286|           105|\n",
      "|    496|     1|  2|         4|     5| 4.294117647058823|           119|\n",
      "|    833|     1|  4|         7|     4|4.0476190476190474|            21|\n",
      "+-------+------+---+----------+------+------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "    SELECT  A.user_id, A.gender, A.age, A.occupation, A.region, B.avg_rating, B.watched_movies\n",
    "    FROM    users_info A\n",
    "            INNER JOIN \n",
    "            (SELECT   user_id, MEAN(rating) AS avg_rating, COUNT(movie_id) AS watched_movies\n",
    "            FROM     ratings_info\n",
    "            GROUP BY user_id) B\n",
    "            ON B.user_id = A.user_id\n",
    "\"\"\"\n",
    "\n",
    "users = spark.sql(query)\n",
    "users.createOrReplaceTempView(\"users_info\")\n",
    "users.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5a3a5b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movie_id: integer (nullable = true)\n",
      " |-- movie_name: string (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- parsed_genre: string (nullable = false)\n",
      " |-- value: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c33b2f",
   "metadata": {},
   "source": [
    "**Avarage ratings per genre**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3538e64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+--------------------+----+---------+------------+-----+\n",
      "|movie_id|      movie_name|               genre|year|     name|parsed_genre|value|\n",
      "+--------+----------------+--------------------+----+---------+------------+-----+\n",
      "|       1|Toy Story (1995)|Animation|Childre...|1995|Toy Story|   Animation|    1|\n",
      "|       1|Toy Story (1995)|Animation|Childre...|1995|Toy Story|  Children's|    1|\n",
      "|       1|Toy Story (1995)|Animation|Childre...|1995|Toy Story|      Comedy|    1|\n",
      "|       2|  Jumanji (1995)|Adventure|Childre...|1995|  Jumanji|   Adventure|    1|\n",
      "|       2|  Jumanji (1995)|Adventure|Childre...|1995|  Jumanji|  Children's|    1|\n",
      "+--------+----------------+--------------------+----+---------+------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM movies_info\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "66852d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+--------------------+\n",
      "|parsed_genre|user_id|avg_rating_per_genre|\n",
      "+------------+-------+--------------------+\n",
      "|      Sci-Fi|      9|   3.888888888888889|\n",
      "|      Sci-Fi|     28|                 3.6|\n",
      "|     Western|     28|                 3.0|\n",
      "|     Fantasy|     37|                 2.0|\n",
      "|   Adventure|     42|  3.8059701492537314|\n",
      "+------------+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT  parsed_genre, user_id,  MEAN(rating) avg_rating_per_genre\n",
    "            FROM    ratings_info A INNER JOIN movies_info B USING (movie_id)\n",
    "            GROUP BY parsed_genre, user_id\n",
    "\"\"\"\n",
    "\n",
    "avg_per_genre = spark.sql(query)\n",
    "avg_per_genre.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "30f71513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------+------------------------+------------------------+-------------------------+---------------------+--------------------+--------------------------+--------------------+----------------------+------------------------+---------------------+----------------------+----------------------+----------------------+---------------------+-----------------------+------------------+----------------------+\n",
      "|user_id|avg_rating_for_Action|avg_rating_for_Adventure|avg_rating_for_Animation|avg_rating_for_Children's|avg_rating_for_Comedy|avg_rating_for_Crime|avg_rating_for_Documentary|avg_rating_for_Drama|avg_rating_for_Fantasy|avg_rating_for_Film-Noir|avg_rating_for_Horror|avg_rating_for_Musical|avg_rating_for_Mystery|avg_rating_for_Romance|avg_rating_for_Sci-Fi|avg_rating_for_Thriller|avg_rating_for_War|avg_rating_for_Western|\n",
      "+-------+---------------------+------------------------+------------------------+-------------------------+---------------------+--------------------+--------------------------+--------------------+----------------------+------------------------+---------------------+----------------------+----------------------+----------------------+---------------------+-----------------------+------------------+----------------------+\n",
      "|    463|                  2.5|                     2.7|                     3.4|       2.3076923076923075|   2.9734513274336285|  3.1666666666666665|                       0.0|  3.3181818181818183|    2.3333333333333335|                     0.0|                  3.0|     3.142857142857143|                  3.25|    2.9565217391304346|   2.5714285714285716|                   3.25| 4.166666666666667|                   3.0|\n",
      "|    496|    4.523809523809524|                    4.52|                     4.7|                      4.0|    4.319148936170213|                 5.0|                       0.0|                4.04|                  3.75|                     3.0|    4.571428571428571|                   1.0|     4.166666666666667|     4.666666666666667|    4.088235294117647|                  4.125|               4.2|                   0.0|\n",
      "|    471|   3.1136363636363638|                     3.0|       4.666666666666667|                      3.5|   3.6956521739130435|                 4.0|                       4.0|   4.194444444444445|    3.1666666666666665|                     5.0|                  3.0|                   2.0|                   4.0|    3.1666666666666665|   3.0384615384615383|      3.588235294117647|               4.4|                   4.5|\n",
      "|   1088|   3.1298076923076925|      3.0163934426229506|       3.161290322580645|       2.8181818181818183|    3.163265306122449|  3.5609756097560976|                       4.0|  3.6674008810572687|     2.735294117647059|       3.869565217391304|   3.0136986301369864|               3.46875|     3.441860465116279|    3.3962264150943398|   3.1881188118811883|      3.325358851674641|3.9365079365079363|     3.526315789473684|\n",
      "|    833|                  4.0|                     4.0|                     0.0|                      0.0|                  3.0|                 0.0|                       0.0|                 4.7|                   0.0|                     0.0|                  0.0|                   5.0|                   0.0|                   5.0|                  4.0|      3.857142857142857| 4.666666666666667|                   5.0|\n",
      "+-------+---------------------+------------------------+------------------------+-------------------------+---------------------+--------------------+--------------------------+--------------------+----------------------+------------------------+---------------------+----------------------+----------------------+----------------------+---------------------+-----------------------+------------------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "excluded = [\"user_id\"]\n",
    "avg_per_genre = avg_per_genre.groupBy(\"user_id\").pivot(\"parsed_genre\").sum(\"avg_rating_per_genre\")\n",
    "columns = {col: 0 for col in avg_per_genre.columns if not(col in excluded)}\n",
    "avg_per_genre = avg_per_genre.fillna(columns)\n",
    "\n",
    "for col in avg_per_genre.columns:\n",
    "    if not(col in excluded):\n",
    "        avg_per_genre = avg_per_genre.withColumnRenamed(col, \"avg_rating_for_\"+col)\n",
    "\n",
    "        \n",
    "avg_per_genre.createOrReplaceTempView(\"avg_info\")\n",
    "avg_per_genre.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "08af41d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- gender: integer (nullable = false)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- occupation: integer (nullable = true)\n",
      " |-- region: integer (nullable = true)\n",
      " |-- avg_rating: double (nullable = true)\n",
      " |-- watched_movies: long (nullable = false)\n",
      " |-- avg_rating_for_Action: double (nullable = false)\n",
      " |-- avg_rating_for_Adventure: double (nullable = false)\n",
      " |-- avg_rating_for_Animation: double (nullable = false)\n",
      " |-- avg_rating_for_Children's: double (nullable = false)\n",
      " |-- avg_rating_for_Comedy: double (nullable = false)\n",
      " |-- avg_rating_for_Crime: double (nullable = false)\n",
      " |-- avg_rating_for_Documentary: double (nullable = false)\n",
      " |-- avg_rating_for_Drama: double (nullable = false)\n",
      " |-- avg_rating_for_Fantasy: double (nullable = false)\n",
      " |-- avg_rating_for_Film-Noir: double (nullable = false)\n",
      " |-- avg_rating_for_Horror: double (nullable = false)\n",
      " |-- avg_rating_for_Musical: double (nullable = false)\n",
      " |-- avg_rating_for_Mystery: double (nullable = false)\n",
      " |-- avg_rating_for_Romance: double (nullable = false)\n",
      " |-- avg_rating_for_Sci-Fi: double (nullable = false)\n",
      " |-- avg_rating_for_Thriller: double (nullable = false)\n",
      " |-- avg_rating_for_War: double (nullable = false)\n",
      " |-- avg_rating_for_Western: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "        SELECT  *\n",
    "        FROM    users_info INNER JOIN avg_info USING (user_id)\n",
    "\"\"\"\n",
    "\n",
    "users = spark.sql(query)\n",
    "users.createOrReplaceTempView(\"users_info\")\n",
    "users.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4f946c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = users.withColumn(\"value\", (users[\"occupation\"]==users[\"occupation\"]).cast(IntegerType()))\n",
    "\n",
    "columns = [col for col in users.columns if not(col in [\"occupation\", \"value\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "103547fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = users.groupBy(columns).pivot(\"occupation\").sum(\"value\")\n",
    "cols = {col: 0 for col in users.columns if not(col in columns)}\n",
    "users = users.fillna(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "250984db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- gender: integer (nullable = false)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- region: integer (nullable = true)\n",
      " |-- avg_rating: double (nullable = true)\n",
      " |-- watched_movies: long (nullable = false)\n",
      " |-- avg_rating_for_Action: double (nullable = false)\n",
      " |-- avg_rating_for_Adventure: double (nullable = false)\n",
      " |-- avg_rating_for_Animation: double (nullable = false)\n",
      " |-- avg_rating_for_Children's: double (nullable = false)\n",
      " |-- avg_rating_for_Comedy: double (nullable = false)\n",
      " |-- avg_rating_for_Crime: double (nullable = false)\n",
      " |-- avg_rating_for_Documentary: double (nullable = false)\n",
      " |-- avg_rating_for_Drama: double (nullable = false)\n",
      " |-- avg_rating_for_Fantasy: double (nullable = false)\n",
      " |-- avg_rating_for_Film-Noir: double (nullable = false)\n",
      " |-- avg_rating_for_Horror: double (nullable = false)\n",
      " |-- avg_rating_for_Musical: double (nullable = false)\n",
      " |-- avg_rating_for_Mystery: double (nullable = false)\n",
      " |-- avg_rating_for_Romance: double (nullable = false)\n",
      " |-- avg_rating_for_Sci-Fi: double (nullable = false)\n",
      " |-- avg_rating_for_Thriller: double (nullable = false)\n",
      " |-- avg_rating_for_War: double (nullable = false)\n",
      " |-- avg_rating_for_Western: double (nullable = false)\n",
      " |-- 0: long (nullable = false)\n",
      " |-- 1: long (nullable = false)\n",
      " |-- 2: long (nullable = false)\n",
      " |-- 3: long (nullable = false)\n",
      " |-- 4: long (nullable = false)\n",
      " |-- 5: long (nullable = false)\n",
      " |-- 6: long (nullable = false)\n",
      " |-- 7: long (nullable = false)\n",
      " |-- 8: long (nullable = false)\n",
      " |-- 9: long (nullable = false)\n",
      " |-- 10: long (nullable = false)\n",
      " |-- 11: long (nullable = false)\n",
      " |-- 12: long (nullable = false)\n",
      " |-- 13: long (nullable = false)\n",
      " |-- 14: long (nullable = false)\n",
      " |-- 15: long (nullable = false)\n",
      " |-- 16: long (nullable = false)\n",
      " |-- 17: long (nullable = false)\n",
      " |-- 18: long (nullable = false)\n",
      " |-- 19: long (nullable = false)\n",
      " |-- 20: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7913f3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    0: \"other\",\n",
    "    1: \"academic/educator\", \n",
    "    2: \"artist\",\n",
    "    3: \"clerical/admin\",\n",
    "    4: \"college/grad student\",\n",
    "    5: \"customer service\",\n",
    "    6: \"doctor/health care\",\n",
    "    7: \"executive/managerial\",\n",
    "    8: \"farmer\",\n",
    "    9: \"homemaker\",\n",
    "    10: \"K-12 student\",\n",
    "    11: \"lawyer\",\n",
    "    12: \"programmer\",\n",
    "    13: \"retired\",\n",
    "    14: \"sales/marketing\",\n",
    "    15: \"scientist\",\n",
    "    16: \"self-employed\",\n",
    "    17: \"technician/engineer\",\n",
    "    18: \"tradesman/craftsman\",\n",
    "    19: \"unemployed\",\n",
    "    20: \"writer\"\n",
    "}\n",
    "\n",
    "for col in cols.keys():\n",
    "    users = users.withColumnRenamed(col, label_mapping[int(col)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fe2c48f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- gender: integer (nullable = false)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- region: integer (nullable = true)\n",
      " |-- avg_rating: double (nullable = true)\n",
      " |-- watched_movies: long (nullable = false)\n",
      " |-- avg_rating_for_Action: double (nullable = false)\n",
      " |-- avg_rating_for_Adventure: double (nullable = false)\n",
      " |-- avg_rating_for_Animation: double (nullable = false)\n",
      " |-- avg_rating_for_Children's: double (nullable = false)\n",
      " |-- avg_rating_for_Comedy: double (nullable = false)\n",
      " |-- avg_rating_for_Crime: double (nullable = false)\n",
      " |-- avg_rating_for_Documentary: double (nullable = false)\n",
      " |-- avg_rating_for_Drama: double (nullable = false)\n",
      " |-- avg_rating_for_Fantasy: double (nullable = false)\n",
      " |-- avg_rating_for_Film-Noir: double (nullable = false)\n",
      " |-- avg_rating_for_Horror: double (nullable = false)\n",
      " |-- avg_rating_for_Musical: double (nullable = false)\n",
      " |-- avg_rating_for_Mystery: double (nullable = false)\n",
      " |-- avg_rating_for_Romance: double (nullable = false)\n",
      " |-- avg_rating_for_Sci-Fi: double (nullable = false)\n",
      " |-- avg_rating_for_Thriller: double (nullable = false)\n",
      " |-- avg_rating_for_War: double (nullable = false)\n",
      " |-- avg_rating_for_Western: double (nullable = false)\n",
      " |-- other: long (nullable = false)\n",
      " |-- academic/educator: long (nullable = false)\n",
      " |-- artist: long (nullable = false)\n",
      " |-- clerical/admin: long (nullable = false)\n",
      " |-- college/grad student: long (nullable = false)\n",
      " |-- customer service: long (nullable = false)\n",
      " |-- doctor/health care: long (nullable = false)\n",
      " |-- executive/managerial: long (nullable = false)\n",
      " |-- farmer: long (nullable = false)\n",
      " |-- homemaker: long (nullable = false)\n",
      " |-- K-12 student: long (nullable = false)\n",
      " |-- lawyer: long (nullable = false)\n",
      " |-- programmer: long (nullable = false)\n",
      " |-- retired: long (nullable = false)\n",
      " |-- sales/marketing: long (nullable = false)\n",
      " |-- scientist: long (nullable = false)\n",
      " |-- self-employed: long (nullable = false)\n",
      " |-- technician/engineer: long (nullable = false)\n",
      " |-- tradesman/craftsman: long (nullable = false)\n",
      " |-- unemployed: long (nullable = false)\n",
      " |-- writer: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a3caa33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|user_id|              year|\n",
      "+-------+------------------+\n",
      "|    148|1985.5959079283887|\n",
      "|    463|1981.9772727272727|\n",
      "|    471|1977.6949152542372|\n",
      "|    496|1989.5643564356435|\n",
      "|    833|         1992.9375|\n",
      "+-------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "        SELECT  user_id, MEAN(year) AS year\n",
    "        FROM    (SELECT * FROM ratings_info WHERE rating>3) A \n",
    "                INNER JOIN \n",
    "                (SELECT movie_id, MEAN(year) year FROM movies_info GROUP BY movie_id) B\n",
    "                USING (movie_id)\n",
    "        GROUP BY user_id\n",
    "\"\"\"\n",
    "\n",
    "year = spark.sql(query)\n",
    "year.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "30405992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+\n",
      "|user_id|year|\n",
      "+-------+----+\n",
      "+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "year[year[\"year\"].isNull()].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a7b8a4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "users.createOrReplaceTempView(\"users_info\")\n",
    "year.createOrReplaceTempView(\"year_info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2aeec73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- gender: integer (nullable = false)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- region: integer (nullable = true)\n",
      " |-- avg_rating: double (nullable = true)\n",
      " |-- watched_movies: long (nullable = false)\n",
      " |-- avg_rating_for_Action: double (nullable = false)\n",
      " |-- avg_rating_for_Adventure: double (nullable = false)\n",
      " |-- avg_rating_for_Animation: double (nullable = false)\n",
      " |-- avg_rating_for_Children's: double (nullable = false)\n",
      " |-- avg_rating_for_Comedy: double (nullable = false)\n",
      " |-- avg_rating_for_Crime: double (nullable = false)\n",
      " |-- avg_rating_for_Documentary: double (nullable = false)\n",
      " |-- avg_rating_for_Drama: double (nullable = false)\n",
      " |-- avg_rating_for_Fantasy: double (nullable = false)\n",
      " |-- avg_rating_for_Film-Noir: double (nullable = false)\n",
      " |-- avg_rating_for_Horror: double (nullable = false)\n",
      " |-- avg_rating_for_Musical: double (nullable = false)\n",
      " |-- avg_rating_for_Mystery: double (nullable = false)\n",
      " |-- avg_rating_for_Romance: double (nullable = false)\n",
      " |-- avg_rating_for_Sci-Fi: double (nullable = false)\n",
      " |-- avg_rating_for_Thriller: double (nullable = false)\n",
      " |-- avg_rating_for_War: double (nullable = false)\n",
      " |-- avg_rating_for_Western: double (nullable = false)\n",
      " |-- other: long (nullable = false)\n",
      " |-- academic/educator: long (nullable = false)\n",
      " |-- artist: long (nullable = false)\n",
      " |-- clerical/admin: long (nullable = false)\n",
      " |-- college/grad student: long (nullable = false)\n",
      " |-- customer service: long (nullable = false)\n",
      " |-- doctor/health care: long (nullable = false)\n",
      " |-- executive/managerial: long (nullable = false)\n",
      " |-- farmer: long (nullable = false)\n",
      " |-- homemaker: long (nullable = false)\n",
      " |-- K-12 student: long (nullable = false)\n",
      " |-- lawyer: long (nullable = false)\n",
      " |-- programmer: long (nullable = false)\n",
      " |-- retired: long (nullable = false)\n",
      " |-- sales/marketing: long (nullable = false)\n",
      " |-- scientist: long (nullable = false)\n",
      " |-- self-employed: long (nullable = false)\n",
      " |-- technician/engineer: long (nullable = false)\n",
      " |-- tradesman/craftsman: long (nullable = false)\n",
      " |-- unemployed: long (nullable = false)\n",
      " |-- writer: long (nullable = false)\n",
      " |-- year: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "        SELECT    *\n",
    "        FROM users_info INNER JOIN year_info USING (user_id)\n",
    "\"\"\"\n",
    "\n",
    "users = spark.sql(query)\n",
    "users.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f0dccbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|region|\n",
      "+------+\n",
      "|     1|\n",
      "|     6|\n",
      "|     3|\n",
      "|     5|\n",
      "|     9|\n",
      "|     4|\n",
      "|     8|\n",
      "|     7|\n",
      "|     2|\n",
      "|     0|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users.select(\"region\").distinct().show(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6e1e9f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "users.toPandas().to_csv(\"./Data/cleaned_data/pivoted_users_features.csv\", header=True)\n",
    "users.createOrReplaceTempView(\"users_info\")\n",
    "sub1.createOrReplaceTempView(\"movies_info\")\n",
    "print(len(sub1.columns))\n",
    "print(len(users.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e3516a",
   "metadata": {},
   "source": [
    "# 5. Joining Features and creating unified dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c23474e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT *\n",
    "        FROM (ratings_info INNER JOIN users_info USING (user_id)) INNER JOIN sub1_info USING (movie_id)\n",
    "\"\"\"\n",
    "\n",
    "result = spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "692f618c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "39f0a5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movie_id: integer (nullable = true)\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      " |-- time_stamp: integer (nullable = true)\n",
      " |-- gender: integer (nullable = false)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- region: integer (nullable = true)\n",
      " |-- avg_rating: double (nullable = true)\n",
      " |-- watched_movies: long (nullable = false)\n",
      " |-- avg_rating_for_Action: double (nullable = false)\n",
      " |-- avg_rating_for_Adventure: double (nullable = false)\n",
      " |-- avg_rating_for_Animation: double (nullable = false)\n",
      " |-- avg_rating_for_Children's: double (nullable = false)\n",
      " |-- avg_rating_for_Comedy: double (nullable = false)\n",
      " |-- avg_rating_for_Crime: double (nullable = false)\n",
      " |-- avg_rating_for_Documentary: double (nullable = false)\n",
      " |-- avg_rating_for_Drama: double (nullable = false)\n",
      " |-- avg_rating_for_Fantasy: double (nullable = false)\n",
      " |-- avg_rating_for_Film-Noir: double (nullable = false)\n",
      " |-- avg_rating_for_Horror: double (nullable = false)\n",
      " |-- avg_rating_for_Musical: double (nullable = false)\n",
      " |-- avg_rating_for_Mystery: double (nullable = false)\n",
      " |-- avg_rating_for_Romance: double (nullable = false)\n",
      " |-- avg_rating_for_Sci-Fi: double (nullable = false)\n",
      " |-- avg_rating_for_Thriller: double (nullable = false)\n",
      " |-- avg_rating_for_War: double (nullable = false)\n",
      " |-- avg_rating_for_Western: double (nullable = false)\n",
      " |-- other: long (nullable = false)\n",
      " |-- academic/educator: long (nullable = false)\n",
      " |-- artist: long (nullable = false)\n",
      " |-- clerical/admin: long (nullable = false)\n",
      " |-- college/grad student: long (nullable = false)\n",
      " |-- customer service: long (nullable = false)\n",
      " |-- doctor/health care: long (nullable = false)\n",
      " |-- executive/managerial: long (nullable = false)\n",
      " |-- farmer: long (nullable = false)\n",
      " |-- homemaker: long (nullable = false)\n",
      " |-- K-12 student: long (nullable = false)\n",
      " |-- lawyer: long (nullable = false)\n",
      " |-- programmer: long (nullable = false)\n",
      " |-- retired: long (nullable = false)\n",
      " |-- sales/marketing: long (nullable = false)\n",
      " |-- scientist: long (nullable = false)\n",
      " |-- self-employed: long (nullable = false)\n",
      " |-- technician/engineer: long (nullable = false)\n",
      " |-- tradesman/craftsman: long (nullable = false)\n",
      " |-- unemployed: long (nullable = false)\n",
      " |-- writer: long (nullable = false)\n",
      " |-- year: double (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- watches: long (nullable = false)\n",
      " |-- avg_rating: double (nullable = true)\n",
      " |-- popularity_per_Action: double (nullable = false)\n",
      " |-- popularity_per_Adventure: double (nullable = false)\n",
      " |-- popularity_per_Animation: double (nullable = false)\n",
      " |-- popularity_per_Children's: double (nullable = false)\n",
      " |-- popularity_per_Comedy: double (nullable = false)\n",
      " |-- popularity_per_Crime: double (nullable = false)\n",
      " |-- popularity_per_Documentary: double (nullable = false)\n",
      " |-- popularity_per_Drama: double (nullable = false)\n",
      " |-- popularity_per_Fantasy: double (nullable = false)\n",
      " |-- popularity_per_Film-Noir: double (nullable = false)\n",
      " |-- popularity_per_Horror: double (nullable = false)\n",
      " |-- popularity_per_Musical: double (nullable = false)\n",
      " |-- popularity_per_Mystery: double (nullable = false)\n",
      " |-- popularity_per_Romance: double (nullable = false)\n",
      " |-- popularity_per_Sci-Fi: double (nullable = false)\n",
      " |-- popularity_per_Thriller: double (nullable = false)\n",
      " |-- popularity_per_War: double (nullable = false)\n",
      " |-- popularity_per_Western: double (nullable = false)\n",
      " |-- rating_per_Action: double (nullable = false)\n",
      " |-- rating_per_Adventure: double (nullable = false)\n",
      " |-- rating_per_Animation: double (nullable = false)\n",
      " |-- rating_per_Children's: double (nullable = false)\n",
      " |-- rating_per_Comedy: double (nullable = false)\n",
      " |-- rating_per_Crime: double (nullable = false)\n",
      " |-- rating_per_Documentary: double (nullable = false)\n",
      " |-- rating_per_Drama: double (nullable = false)\n",
      " |-- rating_per_Fantasy: double (nullable = false)\n",
      " |-- rating_per_Film-Noir: double (nullable = false)\n",
      " |-- rating_per_Horror: double (nullable = false)\n",
      " |-- rating_per_Musical: double (nullable = false)\n",
      " |-- rating_per_Mystery: double (nullable = false)\n",
      " |-- rating_per_Romance: double (nullable = false)\n",
      " |-- rating_per_Sci-Fi: double (nullable = false)\n",
      " |-- rating_per_Thriller: double (nullable = false)\n",
      " |-- rating_per_War: double (nullable = false)\n",
      " |-- rating_per_Western: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9f96941b",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o748.collectToPython.\n: java.io.IOException: java.lang.NullPointerException\r\n\tat org.apache.spark.util.SparkErrorUtils.tryOrIOException(SparkErrorUtils.scala:42)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryOrIOException$(SparkErrorUtils.scala:33)\r\n\tat org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:94)\r\n\tat org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:252)\r\n\tat org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:109)\r\n\tat org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70)\r\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.prepareBroadcast(BroadcastHashJoinExec.scala:188)\r\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.prepareRelation(BroadcastHashJoinExec.scala:200)\r\n\tat org.apache.spark.sql.execution.joins.HashJoin.codegenInner(HashJoin.scala:391)\r\n\tat org.apache.spark.sql.execution.joins.HashJoin.codegenInner$(HashJoin.scala:390)\r\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.codegenInner(BroadcastHashJoinExec.scala:40)\r\n\tat org.apache.spark.sql.execution.joins.HashJoin.doConsume(HashJoin.scala:357)\r\n\tat org.apache.spark.sql.execution.joins.HashJoin.doConsume$(HashJoin.scala:355)\r\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doConsume(BroadcastHashJoinExec.scala:40)\r\n\tat org.apache.spark.sql.execution.CodegenSupport.consume(WholeStageCodegenExec.scala:196)\r\n\tat org.apache.spark.sql.execution.CodegenSupport.consume$(WholeStageCodegenExec.scala:151)\r\n\tat org.apache.spark.sql.execution.InputAdapter.consume(WholeStageCodegenExec.scala:498)\r\n\tat org.apache.spark.sql.execution.InputRDDCodegen.doProduce(WholeStageCodegenExec.scala:485)\r\n\tat org.apache.spark.sql.execution.InputRDDCodegen.doProduce$(WholeStageCodegenExec.scala:458)\r\n\tat org.apache.spark.sql.execution.InputAdapter.doProduce(WholeStageCodegenExec.scala:498)\r\n\tat org.apache.spark.sql.execution.CodegenSupport.$anonfun$produce$1(WholeStageCodegenExec.scala:97)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:246)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:243)\r\n\tat org.apache.spark.sql.execution.CodegenSupport.produce(WholeStageCodegenExec.scala:92)\r\n\tat org.apache.spark.sql.execution.CodegenSupport.produce$(WholeStageCodegenExec.scala:92)\r\n\tat org.apache.spark.sql.execution.InputAdapter.produce(WholeStageCodegenExec.scala:498)\r\n\tat org.apache.spark.sql.execution.joins.HashJoin.doProduce(HashJoin.scala:352)\r\n\tat org.apache.spark.sql.execution.joins.HashJoin.doProduce$(HashJoin.scala:351)\r\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doProduce(BroadcastHashJoinExec.scala:40)\r\n\tat org.apache.spark.sql.execution.CodegenSupport.$anonfun$produce$1(WholeStageCodegenExec.scala:97)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:246)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:243)\r\n\tat org.apache.spark.sql.execution.CodegenSupport.produce(WholeStageCodegenExec.scala:92)\r\n\tat org.apache.spark.sql.execution.CodegenSupport.produce$(WholeStageCodegenExec.scala:92)\r\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.produce(BroadcastHashJoinExec.scala:40)\r\n\tat org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:55)\r\n\tat org.apache.spark.sql.execution.CodegenSupport.$anonfun$produce$1(WholeStageCodegenExec.scala:97)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:246)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:243)\r\n\tat org.apache.spark.sql.execution.CodegenSupport.produce(WholeStageCodegenExec.scala:92)\r\n\tat org.apache.spark.sql.execution.CodegenSupport.produce$(WholeStageCodegenExec.scala:92)\r\n\tat org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:42)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doCodeGen(WholeStageCodegenExec.scala:660)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:723)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:195)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:246)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:243)\r\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:191)\r\n\tat org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:364)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:445)\r\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$executeCollect$1(AdaptiveSparkPlanExec.scala:390)\r\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.withFinalPlanUpdate(AdaptiveSparkPlanExec.scala:418)\r\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.executeCollect(AdaptiveSparkPlanExec.scala:390)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$collectToPython$1(Dataset.scala:4148)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4322)\r\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4320)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4320)\r\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:4145)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:829)\r\nCaused by: java.lang.NullPointerException\r\n\tat org.apache.spark.broadcast.TorrentBroadcast.$anonfun$readBroadcastBlock$2(TorrentBroadcast.scala:255)\r\n\tat org.apache.spark.util.KeyLock.withLock(KeyLock.scala:64)\r\n\tat org.apache.spark.broadcast.TorrentBroadcast.$anonfun$readBroadcastBlock$1(TorrentBroadcast.scala:252)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryOrIOException(SparkErrorUtils.scala:35)\r\n\t... 79 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoPandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./Data/cleaned_data/unified_rating_features.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KD_torch\\lib\\site-packages\\pyspark\\sql\\pandas\\conversion.py:202\u001b[0m, in \u001b[0;36mPandasConversionMixin.toPandas\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    199\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;66;03m# Below is toPandas without Arrow optimization.\u001b[39;00m\n\u001b[1;32m--> 202\u001b[0m rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(rows) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    204\u001b[0m     pdf \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_records(\n\u001b[0;32m    205\u001b[0m         rows, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(rows)), columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    206\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KD_torch\\lib\\site-packages\\pyspark\\sql\\dataframe.py:1261\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1241\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns all the records as a list of :class:`Row`.\u001b[39;00m\n\u001b[0;32m   1242\u001b[0m \n\u001b[0;32m   1243\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[38;5;124;03m[Row(age=14, name='Tom'), Row(age=23, name='Alice'), Row(age=16, name='Bob')]\u001b[39;00m\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1260\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sc):\n\u001b[1;32m-> 1261\u001b[0m     sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollectToPython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, BatchedSerializer(CPickleSerializer())))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KD_torch\\lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KD_torch\\lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KD_torch\\lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o748.collectToPython.\n: java.io.IOException: java.lang.NullPointerException\r\n\tat org.apache.spark.util.SparkErrorUtils.tryOrIOException(SparkErrorUtils.scala:42)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryOrIOException$(SparkErrorUtils.scala:33)\r\n\tat org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:94)\r\n\tat org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:252)\r\n\tat org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:109)\r\n\tat org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70)\r\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.prepareBroadcast(BroadcastHashJoinExec.scala:188)\r\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.prepareRelation(BroadcastHashJoinExec.scala:200)\r\n\tat org.apache.spark.sql.execution.joins.HashJoin.codegenInner(HashJoin.scala:391)\r\n\tat org.apache.spark.sql.execution.joins.HashJoin.codegenInner$(HashJoin.scala:390)\r\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.codegenInner(BroadcastHashJoinExec.scala:40)\r\n\tat org.apache.spark.sql.execution.joins.HashJoin.doConsume(HashJoin.scala:357)\r\n\tat org.apache.spark.sql.execution.joins.HashJoin.doConsume$(HashJoin.scala:355)\r\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doConsume(BroadcastHashJoinExec.scala:40)\r\n\tat org.apache.spark.sql.execution.CodegenSupport.consume(WholeStageCodegenExec.scala:196)\r\n\tat org.apache.spark.sql.execution.CodegenSupport.consume$(WholeStageCodegenExec.scala:151)\r\n\tat org.apache.spark.sql.execution.InputAdapter.consume(WholeStageCodegenExec.scala:498)\r\n\tat org.apache.spark.sql.execution.InputRDDCodegen.doProduce(WholeStageCodegenExec.scala:485)\r\n\tat org.apache.spark.sql.execution.InputRDDCodegen.doProduce$(WholeStageCodegenExec.scala:458)\r\n\tat org.apache.spark.sql.execution.InputAdapter.doProduce(WholeStageCodegenExec.scala:498)\r\n\tat org.apache.spark.sql.execution.CodegenSupport.$anonfun$produce$1(WholeStageCodegenExec.scala:97)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:246)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:243)\r\n\tat org.apache.spark.sql.execution.CodegenSupport.produce(WholeStageCodegenExec.scala:92)\r\n\tat org.apache.spark.sql.execution.CodegenSupport.produce$(WholeStageCodegenExec.scala:92)\r\n\tat org.apache.spark.sql.execution.InputAdapter.produce(WholeStageCodegenExec.scala:498)\r\n\tat org.apache.spark.sql.execution.joins.HashJoin.doProduce(HashJoin.scala:352)\r\n\tat org.apache.spark.sql.execution.joins.HashJoin.doProduce$(HashJoin.scala:351)\r\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doProduce(BroadcastHashJoinExec.scala:40)\r\n\tat org.apache.spark.sql.execution.CodegenSupport.$anonfun$produce$1(WholeStageCodegenExec.scala:97)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:246)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:243)\r\n\tat org.apache.spark.sql.execution.CodegenSupport.produce(WholeStageCodegenExec.scala:92)\r\n\tat org.apache.spark.sql.execution.CodegenSupport.produce$(WholeStageCodegenExec.scala:92)\r\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.produce(BroadcastHashJoinExec.scala:40)\r\n\tat org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:55)\r\n\tat org.apache.spark.sql.execution.CodegenSupport.$anonfun$produce$1(WholeStageCodegenExec.scala:97)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:246)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:243)\r\n\tat org.apache.spark.sql.execution.CodegenSupport.produce(WholeStageCodegenExec.scala:92)\r\n\tat org.apache.spark.sql.execution.CodegenSupport.produce$(WholeStageCodegenExec.scala:92)\r\n\tat org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:42)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doCodeGen(WholeStageCodegenExec.scala:660)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:723)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:195)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:246)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:243)\r\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:191)\r\n\tat org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:364)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:445)\r\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$executeCollect$1(AdaptiveSparkPlanExec.scala:390)\r\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.withFinalPlanUpdate(AdaptiveSparkPlanExec.scala:418)\r\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.executeCollect(AdaptiveSparkPlanExec.scala:390)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$collectToPython$1(Dataset.scala:4148)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4322)\r\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\r\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4320)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4320)\r\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:4145)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:829)\r\nCaused by: java.lang.NullPointerException\r\n\tat org.apache.spark.broadcast.TorrentBroadcast.$anonfun$readBroadcastBlock$2(TorrentBroadcast.scala:255)\r\n\tat org.apache.spark.util.KeyLock.withLock(KeyLock.scala:64)\r\n\tat org.apache.spark.broadcast.TorrentBroadcast.$anonfun$readBroadcastBlock$1(TorrentBroadcast.scala:252)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryOrIOException(SparkErrorUtils.scala:35)\r\n\t... 79 more\r\n"
     ]
    }
   ],
   "source": [
    "result.toPandas().to_csv(\"./Data/cleaned_data/unified_rating_features.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effab320",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
