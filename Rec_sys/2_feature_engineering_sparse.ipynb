{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4866f5e",
   "metadata": {},
   "source": [
    "# 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7b77e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.ml as ml\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5003dc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"YourAppName\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e491689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dfs():\n",
    "    global movies, users, ratings\n",
    "    movies = spark.read.csv(\"./Data/movieLens/movies.dat\", sep=\"::\", encoding=\"latin1\")\n",
    "    movies = movies.toDF(\"movie_id\", \"movie_name\", \"genre\").cache()\n",
    "    movies.createOrReplaceTempView(\"movies_info\")\n",
    "    \n",
    "    users = spark.read.csv(\"./Data/movieLens/users.dat\", sep=\"::\", encoding=\"latin1\")\n",
    "    users = users.toDF(\"user_id\", \"gender\", \"age\", \"occupation\", \"zipcode\").cache()\n",
    "    users.createOrReplaceTempView(\"users_info\")\n",
    "    \n",
    "    ratings = spark.read.csv(\"./Data/movieLens/ratings.dat\", sep=\"::\", encoding=\"latin1\")\n",
    "    ratings = ratings.toDF(\"user_id\", \"movie_id\", \"rating\", \"time_stamp\").cache()\n",
    "    ratings.createOrReplaceTempView(\"ratings_info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "903c27c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db93776e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+\n",
      "|movie_id|          movie_name|               genre|\n",
      "+--------+--------------------+--------------------+\n",
      "|       1|    Toy Story (1995)|Animation|Childre...|\n",
      "|       2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|       3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|       4|Waiting to Exhale...|        Comedy|Drama|\n",
      "|       5|Father of the Bri...|              Comedy|\n",
      "+--------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e51a16a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---+----------+-------+\n",
      "|user_id|gender|age|occupation|zipcode|\n",
      "+-------+------+---+----------+-------+\n",
      "|      1|     F|  1|        10|  48067|\n",
      "|      2|     M| 56|        16|  70072|\n",
      "|      3|     M| 25|        15|  55117|\n",
      "|      4|     M| 45|         7|  02460|\n",
      "|      5|     M| 25|        20|  55455|\n",
      "+-------+------+---+----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c7b23de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------+----------+\n",
      "|user_id|movie_id|rating|time_stamp|\n",
      "+-------+--------+------+----------+\n",
      "|      1|    1193|     5| 978300760|\n",
      "|      1|     661|     3| 978302109|\n",
      "|      1|     914|     3| 978301968|\n",
      "|      1|    3408|     4| 978300275|\n",
      "|      1|    2355|     5| 978824291|\n",
      "+-------+--------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6611a417",
   "metadata": {},
   "source": [
    "# 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045b4abb",
   "metadata": {},
   "source": [
    "## 2.1. Checking Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db1b459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_null(df):\n",
    "    for col in df.columns:\n",
    "        empty = df.filter(df[col].isNull()).count()\n",
    "        print(f\"For columns {col}:\\t{empty} null records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351ed4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_null(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f40f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_null(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bbd8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_null(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3c7a18",
   "metadata": {},
   "source": [
    "## 2.2. Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b5457c",
   "metadata": {},
   "source": [
    "### 2.2.1. User dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5ea154",
   "metadata": {},
   "outputs": [],
   "source": [
    "users.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee258331",
   "metadata": {},
   "source": [
    "**Gender**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9ebe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = users.withColumn(\"gender\", pyspark.sql.functions.when(users[\"gender\"] == 'M', 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fb87cd",
   "metadata": {},
   "source": [
    "**Mapping Age to Age Category**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abf88a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType, IntegerType\n",
    "\n",
    "label_mapping = {\n",
    "    1: 1,\n",
    "    18: 2,\n",
    "    25: 3,\n",
    "    35: 4,\n",
    "    45: 5,\n",
    "    50: 6,\n",
    "    56: 7\n",
    "}\n",
    "\n",
    "age_udf = udf(lambda record: label_mapping[int(record)], IntegerType())\n",
    "users = users.withColumn(\"age\", age_udf(users[\"age\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c863a5d",
   "metadata": {},
   "source": [
    "**Mapping Zipcode to Region**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995a29fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = users.withColumn(\"casted_zipcode\", users[\"zipcode\"].cast(IntegerType()))\n",
    "inspect_null(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1270c584",
   "metadata": {},
   "outputs": [],
   "source": [
    "users.filter(users[\"casted_zipcode\"].isNull()).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2a88b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_region(record):\n",
    "    record = str(record)\n",
    "    return int(record[0])\n",
    "\n",
    "zipcode_udf = udf(lambda record: to_region(record), IntegerType())\n",
    "users = users.withColumn(\"region\", zipcode_udf(users[\"zipcode\"]))\n",
    "users = users.drop(\"zipcode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5661891f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_null(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae53789f",
   "metadata": {},
   "source": [
    "**Asserting that All the data are in integer type with no nulls**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d106bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in users.columns:\n",
    "    users = users.withColumn(col, users[col].cast(IntegerType()))\n",
    "    \n",
    "inspect_null(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b9d0d3",
   "metadata": {},
   "source": [
    "### 2.2.2. For Movies Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8307451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76ffc7b",
   "metadata": {},
   "source": [
    "**Transforming movies_id to integer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772357b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.withColumn(\"movie_id\", movies[\"movie_id\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f190b3",
   "metadata": {},
   "source": [
    "**Parsing movie_name to year and name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b506acab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_date(record):\n",
    "    pattern  = r'\\((\\d{4})\\)'\n",
    "    if re.findall(pattern, record.strip()[-6:]):\n",
    "        return int(record.strip()[-5:-1])\n",
    "    return None\n",
    "\n",
    "def extract_name(record):\n",
    "    pattern  = r'\\((\\d{4})\\)'\n",
    "    if re.findall(pattern, record.strip()[-6:]):\n",
    "        return record.strip()[:-6].strip()\n",
    "    return record\n",
    "\n",
    "# Define UDFs for extract_date and extract_name functions\n",
    "extract_date_udf = udf(lambda record: extract_date(record), IntegerType())\n",
    "extract_name_udf = udf(lambda record: extract_name(record), StringType())\n",
    "\n",
    "movies = movies.withColumn(\"year\", extract_date_udf(movies[\"movie_name\"]))\n",
    "movies = movies.withColumn(\"name\", extract_name_udf(movies[\"movie_name\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122a9707",
   "metadata": {},
   "source": [
    "**Parsing the genre into a serie of genres**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604f87cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.withColumn(\"parsed_genre\", pyspark.sql.functions.explode(pyspark.sql.functions.split(movies[\"genre\"], \"\\\\s*\\\\|\\\\s*\")))\n",
    "movies = movies.withColumn(\"value\", (movies[\"parsed_genre\"]==movies[\"parsed_genre\"]).cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8a5046",
   "metadata": {},
   "source": [
    "### 2.2.3. For Ratings Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3babc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49988ca6",
   "metadata": {},
   "source": [
    "**Casting All the attributes to int type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea30d6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ratings.columns:\n",
    "    ratings = ratings.withColumn(col, ratings[col].cast(IntegerType()))\n",
    "\n",
    "ratings.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5222f8ff",
   "metadata": {},
   "source": [
    "# 3. Saving The cleaned datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c5c80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.toPandas().to_csv(\"./Data/cleaned_data/ratings.csv\", header=True, columns = ratings.columns, index=False)\n",
    "movies.toPandas().to_csv(\"./Data/cleaned_data/movies.csv\", header=True, columns = movies.columns, index=False)\n",
    "users.toPandas().to_csv(\"./Data/cleaned_data/users.csv\", header=True, columns = users.columns, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884bed97",
   "metadata": {},
   "source": [
    "# 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c93ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.createOrReplaceTempView(\"movies_info\")\n",
    "users.createOrReplaceTempView(\"users_info\")\n",
    "ratings.createOrReplaceTempView(\"ratings_info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1da82a",
   "metadata": {},
   "source": [
    "## 4.1. Movies Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3b8b13",
   "metadata": {},
   "source": [
    "**Features used for the movie:**\n",
    "1. year\n",
    "2. genres\n",
    "3. watch_count\n",
    "4. popularity among its genre\n",
    "5. avarage rating\n",
    "6. rating ratio per genre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a103491",
   "metadata": {},
   "source": [
    "**watch count**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d763c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "popularity = spark.sql(\"SELECT movie_id, COUNT(DISTINCT(user_id)) AS watches FROM ratings_info GROUP BY movie_id\")\n",
    "popularity.createOrReplaceTempView(\"popularity_info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6fe95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "popularity.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020beb56",
   "metadata": {},
   "source": [
    "**Popularity among its genre**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8997ecfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    SELECT parsed_genre AS genre, COUNT(user_id) AS genre_count\n",
    "    FROM   ratings_info LEFT JOIN movies_info ON movies_info.movie_id = ratings_info.movie_id  \n",
    "    GROUP BY parsed_genre\n",
    "\"\"\"\n",
    "\n",
    "watches_per_genre = spark.sql(query)\n",
    "watches_per_genre.createOrReplaceTempView(\"watches_per_genre_info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7139064",
   "metadata": {},
   "outputs": [],
   "source": [
    "watches_per_genre.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2d1197",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    SELECT *, watches/genre_count AS popularity_per_genre\n",
    "    FROM    (SELECT movies_info.movie_id AS movie_id, year, parsed_genre, watches\n",
    "             FROM   movies_info INNER JOIN popularity_info ON movies_info.movie_id = popularity_info.movie_id\n",
    "            ) A INNER JOIN \n",
    "            watches_per_genre_info ON A.parsed_genre = watches_per_genre_info.genre\n",
    "\"\"\"\n",
    "\n",
    "df = spark.sql(query)\n",
    "df = df.drop(\"parsed_genre\")\n",
    "df.createOrReplaceTempView(\"df_info\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde96d7e",
   "metadata": {},
   "source": [
    "**Avarage Rating**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8889c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    SELECT movie_id, AVG(rating) AS avg_rating \n",
    "    FROM ratings_info \n",
    "    GROUP BY movie_id\n",
    "\"\"\"\n",
    "\n",
    "avg = spark.sql(query)\n",
    "avg.createOrReplaceTempView(\"avg_info\")\n",
    "avg.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c134950",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    SELECT A.movie_id, genre, year, watches, genre_count, popularity_per_genre, avg_rating\n",
    "    FROM   df_info AS A LEFT JOIN avg_info ON A.movie_id = avg_info.movie_id\n",
    "\"\"\"\n",
    "\n",
    "df = spark.sql(query)\n",
    "df.createOrReplaceTempView(\"df_info\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca76ab60",
   "metadata": {},
   "source": [
    "**rating ratio to genre rating**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88459f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    SELECT A.parsed_genre AS genre, MEAN(B.rating) AS mean_genre_rating\n",
    "    FROM   movies_info AS A JOIN ratings_info B ON A.movie_id = B.movie_id\n",
    "    GROUP BY A.parsed_genre\n",
    "\"\"\"\n",
    "\n",
    "avg = spark.sql(query)\n",
    "avg.createOrReplaceTempView(\"avg_info\")\n",
    "avg.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b63896",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    SELECT A.movie_id, A.genre, A.year, watches, popularity_per_genre, avg_rating, avg_rating/mean_genre_rating AS rating_per_genre\n",
    "    FROM   df_info AS A LEFT JOIN avg_info B ON A.genre = B.genre\n",
    "\"\"\"\n",
    "\n",
    "df = spark.sql(query)\n",
    "df.createOrReplaceTempView(\"df_info\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3587e35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.toPandas().to_csv(\"./Data/cleaned_data/unpivoted_movies_features.csv\", header=True, columns=df.columns, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49eb96b",
   "metadata": {},
   "source": [
    "### 4.1.2. Pivoting the Movies Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07c89f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded = [\"movie_id\", \"year\", \"watches\", \"avg_rating\"]\n",
    "\n",
    "sub1 = df[[\"movie_id\", \"genre\", \"year\", \"watches\", \"avg_rating\", \"popularity_per_genre\"]]\n",
    "sub1 = sub1.groupBy([\"movie_id\", \"year\", \"watches\", \"avg_rating\"]).pivot(\"genre\").sum(\"popularity_per_genre\")\n",
    "\n",
    "columns = {col: 0 for col in sub1.columns if not(col in excluded)}\n",
    "sub1 = sub1.fillna(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66da96d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245b3467",
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded = [\"movie_id\", \"year\", \"watches\", \"avg_rating\"]\n",
    "for col in sub1.columns:\n",
    "    if not(col in excluded):\n",
    "        sub1 = sub1.withColumnRenamed(col, \"popularity_per_\"+col)\n",
    "\n",
    "sub1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18047576",
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded = [\"movie_id\", \"year\"]\n",
    "\n",
    "sub2 = df[[\"movie_id\", \"genre\", \"year\", \"rating_per_genre\"]]\n",
    "sub2 = sub2.groupBy([\"movie_id\", \"year\"]).pivot(\"genre\").sum(\"rating_per_genre\")\n",
    "\n",
    "columns = {col: 0 for col in sub2.columns if not(col in excluded)}\n",
    "sub2 = sub2.fillna(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb55813",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0e1e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded = [\"movie_id\", \"year\"]\n",
    "for col in sub2.columns:\n",
    "    if not(col in excluded):\n",
    "        sub2 = sub2.withColumnRenamed(col, \"rating_per_\"+col)\n",
    "\n",
    "sub2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11205664",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1.createOrReplaceTempView(\"sub1_info\")\n",
    "sub2.createOrReplaceTempView(\"sub2_info\")\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT * \n",
    "        FROM sub1_info INNER JOIN sub2_info\n",
    "        USING (movie_id, year)\n",
    "\"\"\"\n",
    "\n",
    "sub1 = spark.sql(query)\n",
    "sub1.createOrReplaceTempView(\"sub1_info\")\n",
    "sub1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef480276",
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_null(sub1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5795131c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1.toPandas().to_csv(\"./Data/cleaned_data/pivoted_movies_features.csv\", header=True, columns=sub1.columns, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d73841",
   "metadata": {},
   "source": [
    "## 4.2. Users Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854231aa",
   "metadata": {},
   "source": [
    "**Features used for the user:**\n",
    "\n",
    "1. gender\n",
    "2. age class\n",
    "3. Occupation class\n",
    "4. Region\n",
    "5. Avarage ratings\n",
    "6. number of watched movies\n",
    "7. avarage rating per genre\n",
    "8. the mode year of the movies watched\n",
    "9. Median year of the movies watched\n",
    "\n",
    "**For missing category avarage rating & Popularity avarage rating impute with avarage rating of all users**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d75aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "users.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49401211",
   "metadata": {},
   "source": [
    "**Avarage ratings & number of watched movies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30e710b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    SELECT  A.user_id, A.gender, A.age, A.occupation, A.region, B.avg_rating, B.watched_movies\n",
    "    FROM    users_info A\n",
    "            INNER JOIN \n",
    "            (SELECT   user_id, MEAN(rating) AS avg_rating, COUNT(movie_id) AS watched_movies\n",
    "            FROM     ratings_info\n",
    "            GROUP BY user_id) B\n",
    "            ON B.user_id = A.user_id\n",
    "\"\"\"\n",
    "\n",
    "users = spark.sql(query)\n",
    "users.createOrReplaceTempView(\"users_info\")\n",
    "users.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3a5b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c33b2f",
   "metadata": {},
   "source": [
    "**Avarage ratings per genre**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312ba13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM movies_info\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66852d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT  parsed_genre, user_id,  MEAN(rating) avg_rating_per_genre\n",
    "            FROM    ratings_info A INNER JOIN movies_info B USING (movie_id)\n",
    "            GROUP BY parsed_genre, user_id\n",
    "\"\"\"\n",
    "\n",
    "avg_per_genre = spark.sql(query)\n",
    "avg_per_genre.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f71513",
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded = [\"user_id\"]\n",
    "avg_per_genre = avg_per_genre.groupBy(\"user_id\").pivot(\"parsed_genre\").sum(\"avg_rating_per_genre\")\n",
    "columns = {col: 0 for col in avg_per_genre.columns if not(col in excluded)}\n",
    "avg_per_genre = avg_per_genre.fillna(columns)\n",
    "\n",
    "for col in avg_per_genre.columns:\n",
    "    if not(col in excluded):\n",
    "        avg_per_genre = avg_per_genre.withColumnRenamed(col, \"avg_rating_for_\"+col)\n",
    "\n",
    "        \n",
    "avg_per_genre.createOrReplaceTempView(\"avg_info\")\n",
    "avg_per_genre.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08af41d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT  *\n",
    "        FROM    users_info INNER JOIN avg_info USING (user_id)\n",
    "\"\"\"\n",
    "\n",
    "users = spark.sql(query)\n",
    "users.createOrReplaceTempView(\"users_info\")\n",
    "users.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f946c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = users.withColumn(\"value\", (users[\"occupation\"]==users[\"occupation\"]).cast(IntegerType()))\n",
    "\n",
    "columns = [col for col in users.columns if not(col in [\"occupation\", \"value\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103547fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = users.groupBy(columns).pivot(\"occupation\").sum(\"value\")\n",
    "cols = {col: 0 for col in users.columns if not(col in columns)}\n",
    "users = users.fillna(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250984db",
   "metadata": {},
   "outputs": [],
   "source": [
    "users.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7913f3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    0: \"other\",\n",
    "    1: \"academic/educator\", \n",
    "    2: \"artist\",\n",
    "    3: \"clerical/admin\",\n",
    "    4: \"college/grad student\",\n",
    "    5: \"customer service\",\n",
    "    6: \"doctor/health care\",\n",
    "    7: \"executive/managerial\",\n",
    "    8: \"farmer\",\n",
    "    9: \"homemaker\",\n",
    "    10: \"K-12 student\",\n",
    "    11: \"lawyer\",\n",
    "    12: \"programmer\",\n",
    "    13: \"retired\",\n",
    "    14: \"sales/marketing\",\n",
    "    15: \"scientist\",\n",
    "    16: \"self-employed\",\n",
    "    17: \"technician/engineer\",\n",
    "    18: \"tradesman/craftsman\",\n",
    "    19: \"unemployed\",\n",
    "    20: \"writer\"\n",
    "}\n",
    "\n",
    "for col in cols.keys():\n",
    "    users = users.withColumnRenamed(col, label_mapping[int(col)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2c48f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "users.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3caa33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT  user_id, MEAN(year) AS year\n",
    "        FROM    (SELECT * FROM ratings_info WHERE rating>3) A \n",
    "                INNER JOIN \n",
    "                (SELECT movie_id, MEAN(year) year FROM movies_info GROUP BY movie_id) B\n",
    "                USING (movie_id)\n",
    "        GROUP BY user_id\n",
    "\"\"\"\n",
    "\n",
    "year = spark.sql(query)\n",
    "year.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30405992",
   "metadata": {},
   "outputs": [],
   "source": [
    "year[year[\"year\"].isNull()].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8a4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "users.createOrReplaceTempView(\"users_info\")\n",
    "year.createOrReplaceTempView(\"year_info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aeec73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT    *\n",
    "        FROM users_info INNER JOIN year_info USING (user_id)\n",
    "\"\"\"\n",
    "\n",
    "users = spark.sql(query)\n",
    "users.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dccbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "users.select(\"region\").distinct().show(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1e9f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "users.toPandas().to_csv(\"./Data/cleaned_data/pivoted_users_features.csv\", header=True, columns=users.columns, index=False)\n",
    "users.createOrReplaceTempView(\"users_info\")\n",
    "sub1.createOrReplaceTempView(\"movies_info\")\n",
    "print(len(sub1.columns))\n",
    "print(len(users.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2f8872",
   "metadata": {},
   "source": [
    "# 5. Joining Features and creating unified dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05834a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT *\n",
    "        FROM (ratings_info INNER JOIN users_info USING (user_id)) INNER JOIN sub1_info USING (movie_id)\n",
    "\"\"\"\n",
    "\n",
    "result = spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7595cb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036884ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb013da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.toPandas().to_csv(\"./Data/cleaned_data/unified_rating_features.csv\", header=True, columns=result.columns, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
